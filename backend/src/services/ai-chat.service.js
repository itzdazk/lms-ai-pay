// src/services/ai-chat.service.js
import { prisma } from '../config/database.config.js'
import knowledgeBaseService from './knowledge-base.service.js'
import ollamaService from './ollama.service.js'
import logger from '../config/logger.config.js'
import config from '../config/app.config.js'
import { HTTP_STATUS, AI_INTERACTION_TYPES } from '../config/constants.js'

class AIChatService {
    /**
     * Helper: Verify conversation access
     * - If conversation.userId is null: public advisor conversation, allow access
     * - If conversation.userId is set: must match current userId
     * @returns {Promise<Object>} conversation object
     * @throws Error if conversation not found or access denied
     */
    async verifyConversationAccess(conversationId, userId) {
        const conversation = await prisma.conversation.findUnique({
            where: { id: conversationId }
        })

        if (!conversation) {
            const error = new Error('Conversation not found')
            error.statusCode = 404
            throw error
        }

        // Public advisor conversation (userId = null) - allow access
        if (conversation.userId === null) {
            return conversation
        }

        // Private conversation - must match current user
        if (conversation.userId !== userId) {
            const error = new Error('Access denied: This conversation belongs to another user')
            error.statusCode = 403
            throw error
        }

        return conversation
    }
    /**
     * T·∫°o conversation m·ªõi
     */
    async createConversation(userId, data = {}) {
        try {
            const { courseId, lessonId, title, mode = 'general' } = data

            // Validate courseId and lessonId exist (if provided)
            let validCourseId = null
            let validLessonId = null
            let course = null
            let lesson = null

            if (courseId) {
                course = await prisma.course.findUnique({
                    where: { id: courseId },
                    select: { id: true, title: true },
                })
                if (course) {
                    validCourseId = courseId
                } else {
                    const error = new Error('Course not found')
                    error.statusCode = HTTP_STATUS.NOT_FOUND
                    throw error
                }
            }

            if (lessonId) {
                lesson = await prisma.lesson.findUnique({
                    where: { id: lessonId },
                    select: { id: true, title: true, courseId: true },
                })
                if (lesson) {
                    validLessonId = lessonId
                    // If lesson exists but courseId doesn't match, use lesson's courseId
                    if (!validCourseId && lesson.courseId) {
                        const lessonCourse = await prisma.course.findUnique({
                            where: { id: lesson.courseId },
                            select: { id: true, title: true },
                        })
                        if (lessonCourse) {
                            validCourseId = lesson.courseId
                            course = lessonCourse
                        }
                    }
                } else {
                    const error = new Error('Lesson not found')
                    error.statusCode = HTTP_STATUS.NOT_FOUND
                    throw error
                }
            }

            // Auto-generate title n·∫øu kh√¥ng c√≥
            let conversationTitle = title

            if (!conversationTitle) {
                if (course) {
                    conversationTitle = `Chat v·ªÅ ${course.title}`
                } else if (lesson) {
                    conversationTitle = `Chat v·ªÅ ${lesson.title}`
                } else {
                    conversationTitle = 'Tr√≤ chuy·ªán chung'
                }
            }

            // Determine context type
            let contextType = AI_INTERACTION_TYPES.GENERAL_CHAT
            if (validLessonId) {
                contextType = AI_INTERACTION_TYPES.LESSON_HELP
            } else if (validCourseId) {
                contextType = AI_INTERACTION_TYPES.COURSE_OVERVIEW
            }

            const conversation = await prisma.conversation.create({
                data: {
                    userId,
                    courseId: validCourseId,
                    lessonId: validLessonId,
                    title: conversationTitle,
                    contextType,
                    mode, // Add mode from data or default to 'general'
                    aiModel: config.OLLAMA_MODEL || 'llama3.1:latest', // Use Ollama model name
                    isActive: true,
                    isArchived: false,
                    lastMessageAt: new Date(),
                },
                include: {
                    course: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                    lesson: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                },
            })

            // Create an initial assistant greeting message so AI is the first sender
            try {
                const greetingText = (() => {
                    if (lesson) {
                        return `Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p v·ªÅ b√†i h·ªçc "${lesson.title}" v√† h·ªó tr·ª£ h·ªçc t·∫≠p. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?`
                    }
                    if (course) {
                        return `Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p v·ªÅ kh√≥a h·ªçc "${course.title}" v√† h·ªó tr·ª£ h·ªçc t·∫≠p. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?`
                    }
                    return 'Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p th·∫Øc m·∫Øc, h·ªó tr·ª£ h·ªçc t·∫≠p v√† t∆∞ v·∫•n l·ªô tr√¨nh. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?'
                })()

                await prisma.chatMessage.create({
                    data: {
                        conversationId: conversation.id,
                        senderType: 'ai',
                        message: greetingText,
                        messageType: 'text',
                    },
                })

                // Update lastMessageAt to the greeting timestamp
                await prisma.conversation.update({
                    where: { id: conversation.id },
                    data: { lastMessageAt: new Date() },
                })
            } catch (greetErr) {
                logger.warn('Failed to create initial AI greeting message:', greetErr)
            }

            logger.info(
                `Created conversation ${conversation.id} for user ${userId}`
            )
            return conversation
        } catch (error) {
            logger.error('Error creating conversation:', error)
            throw error
        }
    }

    /**
     * G·ª≠i message v√† nh·∫≠n response
     */
    async sendMessage(userId, conversationId, messageText, mode = 'course', lessonId = null) {
        try {
            // 1. Verify conversation access (handles both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            // 2. L∆∞u message c·ªßa user
            const userMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'user',
                    message: messageText,
                    messageType: 'text',
                },
            })

            // 3. Build context t·ª´ knowledge base (with timing)
            const contextStartTime = Date.now()
            // Pass mode and lessonId so knowledgeBaseService can use dynamic lessonId
            const context = await knowledgeBaseService.buildContext(
                userId,
                messageText,
                conversationId,
                { mode, dynamicLessonId: lessonId }
            )
            const contextDuration = Date.now() - contextStartTime
            logger.debug(`Knowledge base context built in ${contextDuration}ms`)

            // 4. Get conversation history for context (use knowledge base service)
            const conversationHistory =
                await knowledgeBaseService.getConversationHistory(
                    conversationId,
                    10
                )

            // 5. Generate response using Ollama (with improved fallback to template)
            let responseData
            let usedOllama = false
            let fallbackReason = null
            const responseStartTime = Date.now()

            try {
                // Check if Ollama is available (for all modes including advisor)
                const healthCheckStart = Date.now()
                const isOllamaAvailable = ollamaService.enabled && await ollamaService.checkHealth()
                const healthCheckDuration = Date.now() - healthCheckStart

                if (isOllamaAvailable) {
                    try {
                        // Set timeout for Ollama generation
                        const generationTimeout = 120000 // 120s
                        const timeoutPromise = new Promise((_, reject) => {
                            setTimeout(
                                () =>
                                    reject(
                                        new Error(
                                            'Ollama generation timeout'
                                        )
                                    ),
                                generationTimeout
                            )
                        })

                        // For advisor mode, use specialized generation
                        let generationPromise
                        if (mode === 'advisor') {
                            // Advisor mode: fetch courses first, then use Ollama to generate smart response
                            const availableCourses = context.searchResults?.courses || []
                            generationPromise = this.generateAdvisorResponse(
                                availableCourses,
                                messageText
                            )
                        } else {
                            // Other modes: use standard Ollama generation
                            generationPromise = this.generateOllamaResponse(
                                messageText,
                                conversationHistory,
                                context,
                                mode
                            )
                        }

                        responseData = await Promise.race([
                            generationPromise,
                            timeoutPromise,
                        ])
                        usedOllama = true
                        const responseDuration =
                            Date.now() - responseStartTime
                        logger.info(
                            `Response generated in ${responseDuration}ms (mode: ${mode}) ` +
                                `(health check: ${healthCheckDuration}ms, ` +
                                `hasKnowledgeBase: ${context.searchResults.totalResults > 0})`
                        )
                    } catch (ollamaError) {
                        const errorDuration = Date.now() - responseStartTime
                        fallbackReason =
                            ollamaError.message || 'Unknown error'

                        // Log error with context
                        if (ollamaError.message?.includes('timeout')) {
                            logger.warn(
                                `Ollama generation timeout after ${errorDuration}ms, falling back to template`
                            )
                        } else {
                            logger.error(
                                `Ollama generation failed after ${errorDuration}ms, falling back to template:`,
                                ollamaError.message,
                                ollamaError.stack
                            )
                        }

                        // Fallback to template with error context
                        responseData = this.generateTemplateResponse(
                            context,
                            messageText,
                            { error: fallbackReason }
                        )
                    }
                } else {
                    const checkDuration = Date.now() - responseStartTime
                    fallbackReason = 'Ollama service unavailable'
                    logger.warn(
                        `Ollama not available (checked in ${checkDuration}ms), falling back to template response`
                    )
                    responseData = this.generateTemplateResponse(
                        context,
                        messageText,
                        { reason: fallbackReason }
                    )
                }
            } catch (error) {
                // Catch-all error handler
                fallbackReason = error.message || 'Unexpected error'
                logger.error(
                    `Error generating response (${fallbackReason}), using template fallback:`,
                    error.message,
                    error.stack
                )
                // Fallback to template response
                responseData = this.generateTemplateResponse(
                    context,
                    messageText,
                    { error: fallbackReason }
                )
            }

            // 6. L∆∞u AI response
            const aiMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'ai',
                    message: responseData.text,
                    messageType: 'text',
                    metadata: {
                        sources: responseData.sources,
                        suggestedActions: responseData.suggestedActions,
                        usedOllama,
                        fallbackReason: fallbackReason || null,
                        responseTime: Date.now() - responseStartTime,
                        mode,
                    },
                },
            })

            // 7. Update conversation last message time
            await prisma.conversation.update({
                where: { id: conversationId },
                data: { lastMessageAt: new Date() },
            })

            logger.info(`Sent message in conversation ${conversationId}`)

            return {
                userMessage,
                aiMessage,
                context: {
                    hasResults: context.searchResults.totalResults > 0,
                    totalResults: context.searchResults.totalResults,
                },
            }
        } catch (error) {
            logger.error('Error sending message:', error)
            throw error
        }
    }

    /**
     * Send message with streaming response (for better UX)
     */
    async sendMessageStream(userId, conversationId, messageText, mode = 'course', onChunk, lessonId = null) {
        try {
            // 1. Verify conversation access (handles both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            // 2. L∆∞u message c·ªßa user
            const userMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'user',
                    message: messageText,
                    messageType: 'text',
                },
            })

            // Send user message chunk
            onChunk({
                type: 'user_message',
                data: userMessage,
            })

            // 3. Build context t·ª´ knowledge base (fast, with cache)
            const context = await knowledgeBaseService.buildContext(
                userId,
                messageText,
                conversationId,
                { mode, dynamicLessonId: lessonId }
            )

            // 4. Get conversation history
            const conversationHistory =
                await knowledgeBaseService.getConversationHistory(
                    conversationId,
                    5 // Reduced from 10 to speed up
                )

            // 5. Generate streaming response using Ollama
            let fullResponse = ''
            let sources = []
            let suggestedActions = []
            let streamingError = null
            let usedOllama = false

            try {
                if (ollamaService.enabled) {
                    const isOllamaAvailable = await ollamaService.checkHealth()
                    if (isOllamaAvailable) {
                        // Build system prompt
                        const systemPrompt =
                            ollamaService.buildSystemPrompt(context, mode)

                        // Stream response from Ollama
                        try {
                            for await (const chunk of ollamaService.generateResponseStream(
                                messageText,
                                conversationHistory,
                                systemPrompt
                            )) {
                                fullResponse += chunk
                                onChunk({
                                    type: 'ai_chunk',
                                    chunk: chunk,
                                    accumulated: fullResponse,
                                })
                            }

                            usedOllama = true

                            // Extract sources and actions from context
                            if (context.searchResults.transcripts.length > 0) {
                                sources.push(
                                    ...context.searchResults.transcripts
                                        .slice(0, 3)
                                        .map((t) => ({
                                            type: 'transcript',
                                            lessonId: t.lessonId,
                                            lessonTitle: t.lessonTitle,
                                            courseId: t.courseId,
                                            courseTitle: t.courseTitle,
                                            timestamp: t.timestamp,
                                            videoUrl: t.videoUrl,
                                            excerpt: t.excerpt,
                                        }))
                                )
                            }
                            if (context.searchResults.lessons.length > 0) {
                                sources.push(
                                    ...context.searchResults.lessons
                                        .slice(0, 2)
                                        .map((l) => ({
                                            type: 'lesson',
                                            lessonId: l.id,
                                            lessonTitle: l.title,
                                            courseId: l.courseId,
                                            courseTitle: l.course?.title,
                                        }))
                                )
                            }

                            // Build suggested actions
                            if (context.searchResults.transcripts.length > 0) {
                                const topTranscript =
                                    context.searchResults.transcripts[0]
                                suggestedActions.push({
                                    type: 'watch_video',
                                    label: 'Xem video',
                                    url: topTranscript.videoUrl,
                                    timestamp: topTranscript.startTime,
                                })
                            }
                            if (context.searchResults.lessons.length > 0) {
                                suggestedActions.push({
                                    type: 'view_lesson',
                                    label: 'Xem b√†i h·ªçc',
                                    lessonId:
                                        context.searchResults.lessons[0].id,
                                })
                            }
                        } catch (streamError) {
                            streamingError = streamError
                            logger.error(
                                'Error during Ollama streaming:',
                                streamError
                            )
                            // Continue to fallback
                        }
                    }

                    // Fallback to template if Ollama not available or streaming failed
                    if (
                        !isOllamaAvailable ||
                        streamingError ||
                        !fullResponse.trim()
                    ) {
                        logger.warn(
                            'Falling back to template response (Ollama unavailable or streaming failed)'
                        )
                        const templateResponse = this.generateTemplateResponse(
                            context,
                            messageText
                        )
                        fullResponse = templateResponse.text
                        sources = templateResponse.sources || []
                        suggestedActions =
                            templateResponse.suggestedActions || []

                        // Send as single chunk if not already streaming
                        if (
                            !fullResponse.includes('\n') ||
                            fullResponse.length < 100
                        ) {
                            onChunk({
                                type: 'ai_chunk',
                                chunk: fullResponse,
                                accumulated: fullResponse,
                            })
                        }
                    }
                } else {
                    // Ollama disabled, use template
                    const templateResponse = this.generateTemplateResponse(
                        context,
                        messageText
                    )
                    fullResponse = templateResponse.text
                    sources = templateResponse.sources || []
                    suggestedActions = templateResponse.suggestedActions || []
                    onChunk({
                        type: 'ai_chunk',
                        chunk: fullResponse,
                        accumulated: fullResponse,
                    })
                }
            } catch (error) {
                logger.error('Error in streaming response:', error)
                // Fallback to template
                const templateResponse = this.generateTemplateResponse(
                    context,
                    messageText
                )
                fullResponse = templateResponse.text
                sources = templateResponse.sources || []
                suggestedActions = templateResponse.suggestedActions || []
                onChunk({
                    type: 'ai_chunk',
                    chunk: fullResponse,
                    accumulated: fullResponse,
                })
            }

            // 6. L∆∞u AI response
            const aiMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'ai',
                    message: fullResponse,
                    messageType: 'text',
                    metadata: {
                        sources,
                        suggestedActions,
                        usedOllama,
                        fallbackReason: streamingError ? (streamingError.message || String(streamingError)) : null,
                        responseTime: Date.now() - responseStartTime,
                        mode,
                    },
                },
            })

            // 7. Update conversation
            await prisma.conversation.update({
                where: { id: conversationId },
                data: { lastMessageAt: new Date() },
            })

            // Send final message
            onChunk({
                type: 'ai_message',
                data: aiMessage,
            })

            logger.info(`Streamed message in conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error streaming message:', error)
            throw error
        }
    }

    /**
     * Generate response using Ollama with knowledge base context
     */
    async generateOllamaResponse(messageText, conversationHistory, context, mode = 'course') {
        try {
            // Build system prompt with knowledge base
            const systemPrompt = ollamaService.buildSystemPrompt(context, mode)

            // Generate response from Ollama
            const aiResponse = await ollamaService.generateResponse(
                messageText,
                conversationHistory,
                systemPrompt
            )

            // Extract sources from context
            const sources = []
            if (context.searchResults.transcripts.length > 0) {
                sources.push(
                    ...context.searchResults.transcripts
                        .slice(0, 3)
                        .map((t) => ({
                            type: 'transcript',
                            lessonId: t.lessonId,
                            lessonTitle: t.lessonTitle,
                            courseId: t.courseId,
                            courseTitle: t.courseTitle,
                            timestamp: t.timestamp,
                            videoUrl: t.videoUrl,
                            excerpt: t.excerpt,
                        }))
                )
            }
            if (context.searchResults.lessons.length > 0) {
                sources.push(
                    ...context.searchResults.lessons.slice(0, 2).map((l) => ({
                        type: 'lesson',
                        lessonId: l.id,
                        lessonTitle: l.title,
                        courseId: l.courseId,
                        courseTitle: l.course.title,
                    }))
                )
            }

            // Build suggested actions based on search results
            const suggestedActions = []
            if (context.searchResults.transcripts.length > 0) {
                const topTranscript = context.searchResults.transcripts[0]
                suggestedActions.push({
                    type: 'watch_video',
                    label: 'Xem video',
                    url: topTranscript.videoUrl,
                    timestamp: topTranscript.startTime,
                })
            }
            if (context.searchResults.lessons.length > 0) {
                suggestedActions.push({
                    type: 'view_lesson',
                    label: 'Xem b√†i h·ªçc',
                    lessonId: context.searchResults.lessons[0].id,
                })
            }

            // Prefix clarity for lesson mode: always state which lesson/course
            let prefix = ''
            if (mode === 'course') {
                const lessonTitle =
                    context?.searchResults?.transcripts?.[0]?.lessonTitle ||
                    context?.userContext?.currentLesson?.title ||
                    null
                const courseTitle =
                    context?.searchResults?.transcripts?.[0]?.courseTitle ||
                    context?.userContext?.currentCourse?.title ||
                    null

                if (lessonTitle || courseTitle) {
                    prefix += `üîé Ng·ªØ c·∫£nh: B√†i h·ªçc${lessonTitle ? ` "${lessonTitle}"` : ''}${courseTitle ? ` trong kh√≥a "${courseTitle}"` : ''}.\n\n`
                }
                // If nothing found in this lesson, state it clearly and suggest options
                const hasResults = (context?.searchResults?.totalResults || 0) > 0
                if (!hasResults && lessonTitle) {
                    prefix += `‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung li√™n quan trong b√†i h·ªçc n√†y. B·∫°n c√≥ th·ªÉ:\n- Chuy·ªÉn sang t√πy ch·ªçn "T·ªïng quan" ƒë·ªÉ h·ªèi chung\n- Ho·∫∑c m√¥ t·∫£ chi ti·∫øt h∆°n c√¢u h·ªèi\n\n`
                }
            }

            return {
                text: prefix + aiResponse,
                sources: sources.slice(0, 5), // Limit to 5 sources
                suggestedActions,
            }
        } catch (error) {
            logger.error('Error in generateOllamaResponse:', error)
            throw error
        }
    }

    // getConversationHistory moved to knowledgeBaseService to avoid duplication

    /**
     * Generate template response (fallback method)
     * @param {Object} context - Knowledge base context
     * @param {string} query - User query
     * @param {Object} options - Additional options (error, reason)
     */
    async generateTemplateResponse(context, query, options = {}) {
        const { searchResults, userContext, mode } = context

        // ADVISOR MODE: Recommend courses based on search results
        if (mode === 'advisor') {
            return await this.generateAdvisorResponse(searchResults.courses, query)
        }

        // If in general mode, return a friendly conversational fallback
        if (mode === 'general') {
            return this.generateGeneralFallbackResponse(query)
        }

        // CASE 1: T√¨m th·∫•y trong TRANSCRIPT (Best case!)
        if (searchResults.transcripts.length > 0) {
            return this.generateTranscriptResponse(
                searchResults.transcripts,
                query
            )
        }

        // CASE 2: T√¨m th·∫•y trong LESSONS
        if (searchResults.lessons.length > 0) {
            return this.generateLessonResponse(
                searchResults.lessons,
                query,
                userContext
            )
        }

        // CASE 3: T√¨m th·∫•y trong COURSES
        if (searchResults.courses.length > 0) {
            return this.generateCourseResponse(searchResults.courses, query)
        }

        // CASE 4: Kh√¥ng t√¨m th·∫•y g√¨ - nh∆∞ng n·∫øu ƒëang h·ªèi v·ªÅ n·ªôi dung b√†i h·ªçc v√† c√≥ currentLesson,
        // th√¨ tr·∫£ v·ªÅ th√¥ng tin t·ª´ lesson content/description
        const isAskingAboutContent =
            /n·ªôi dung|content|b√†i h·ªçc n√†y|lesson/i.test(query)
        if (isAskingAboutContent && userContext.currentLesson) {
            return this.generateLessonContentResponse(
                userContext.currentLesson,
                query
            )
        }

        // CASE 5: Kh√¥ng t√¨m th·∫•y g√¨
        return this.generateNoResultResponse(query, userContext)
    }

    /**
     * Response cho advisor mode - s·ª≠ d·ª•ng LLM ƒë·ªÉ hi·ªÉu context nh∆∞ng ch·ªâ g·ª£i √Ω kh√≥a h·ªçc th·ª±c
     */
    async generateAdvisorResponse(courses, query, conversationHistory = []) {
        // Check if query is greeting or learning-related
        const isGreeting = this._isGreeting(query)
        
        if (isGreeting) {
            // For greetings, return welcome message
            const text = `üëã Xin ch√†o! T√¥i l√† Tr·ª£ l√Ω AI, s·∫µn s√†ng gi√∫p b·∫°n t√¨m kh√≥a h·ªçc l·∫≠p tr√¨nh ph√π h·ª£p.

üéØ H√£y cho t√¥i bi·∫øt:
- B·∫°n mu·ªën h·ªçc v·ªÅ lƒ©nh v·ª±c g√¨ trong l·∫≠p tr√¨nh? (Web, Mobile, Data, AI, Game, v.v.)
- Level hi·ªán t·∫°i c·ªßa b·∫°n ra sao? (C∆° b·∫£n/Trung c·∫•p/N√¢ng cao)
- B·∫°n c√≥ bao nhi√™u th·ªùi gian ƒë·ªÉ h·ªçc?

D·ª±a tr√™n th√¥ng tin c·ªßa b·∫°n, t√¥i s·∫Ω g·ª£i √Ω nh·ªØng kh√≥a h·ªçc t·ªët nh·∫•t! üí°`
            return {
                text,
                sources: [],
                suggestedActions: []
            }
        }

        // For learning-related queries, use LLM to understand context
        // Then show real courses with intelligent explanation
        try {
            const availableCourses = courses && courses.length > 0 ? courses : []

            // Filter courses that are relevant to the user's intent
            const relevantCourses = availableCourses.filter((course) =>
                this._isCourseRelevant(query, course)
            )

            // Build a prompt that prevents hallucination and only uses relevant courses
            const coursesForPrompt = relevantCourses.length > 0 ? relevantCourses : []
            const coursesList = coursesForPrompt
                .map((c, i) => `${i + 1}. ${c.title} (${c.durationHours}h, ${c.totalLessons} b√†i h·ªçc)`)
                .join('\n')

            const prompt = `B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n kh√≥a h·ªçc l·∫≠p tr√¨nh. Ng∆∞·ªùi d√πng n√≥i: "${query}"

Kh√≥a h·ªçc c√≥ s·∫µn (ch·ªâ c√°c kh√≥a li√™n quan):
${coursesList || 'Kh√¥ng c√≥ kh√≥a h·ªçc n√†o ph√π h·ª£p'}

H√£y:
1. X√°c nh·∫≠n/hi·ªÉu y√™u c·∫ßu c·ªßa h·ªç (v√≠ d·ª•: "B·∫°n mu·ªën h·ªçc v·ªÅ game development")
2. Gi·∫£i th√≠ch kh√≥a h·ªçc n√†o ph√π h·ª£p NH·∫§T v·ªõi nhu c·∫ßu (ho·∫∑c t·∫°i sao kh√¥ng c√≥ kh√≥a h·ªçc ph√π h·ª£p)
3. N·∫øu kh√¥ng c√≥ kh√≥a h·ªçc ƒë√∫ng, h√£y g·ª£i √Ω kh√≥a h·ªçc c√≥ li√™n quan l√†m n·ªÅn t·∫£ng
4. H·ªèi c√¢u h·ªèi ti·∫øp theo ƒë·ªÉ hi·ªÉu r√µ h∆°n

Ch·ªâ nh·∫Øc ƒë·∫øn kh√≥a h·ªçc c√≥ trong danh s√°ch. KH√îNG t·∫°o ra kh√≥a h·ªçc m·ªõi.`

            // Use Ollama to understand context and generate explanation
            const contextResponse = await ollamaService.generateResponse(prompt)
            let advisorMessage = contextResponse

            logger.info(`‚úÖ Ollama used for advisor response generation`)

            // Include relevant courses only when we found matches
            if (relevantCourses.length > 0) {
                advisorMessage += `\n\nT√¨m th·∫•y ${relevantCourses.length} kh√≥a h·ªçc ph√π h·ª£p. Xem danh s√°ch b√™n d∆∞·ªõi üëá`
            }

            // Build sources from courses
            const sources = relevantCourses.slice(0, 4).map((course) => ({
                type: 'course',
                courseId: course.id,
                courseTitle: course.title,
                courseSlug: course.slug,
                level: course.level,
                price: course.price,
                discountPrice: course.discountPrice,
                rating: course.ratingAvg,
                ratingCount: course.ratingCount,
                enrolledCount: course.enrolledCount,
                duration: course.durationHours,
                lessons: course.totalLessons,
                description: course.shortDescription,
                thumbnail: course.thumbnailUrl,
                instructor: course.instructor,
            }))

            // If no relevant courses, add a follow-up prompt instead of empty list
            if (relevantCourses.length === 0) {
                advisorMessage += `\n\nHi·ªán ch∆∞a c√≥ kh√≥a h·ªçc kh·ªõp v·ªõi y√™u c·∫ßu c·ªßa b·∫°n. H√£y cho t√¥i bi·∫øt th√™m: b·∫°n mu·ªën h·ªçc ng√¥n ng·ªØ n√†o (Python, JavaScript, v.v.) v√† m·ª•c ti√™u c·ª• th·ªÉ (AI, Data, Web, Game)?`
            }

            return { text: advisorMessage, sources }
        } catch (error) {
            logger.error('Error in generateAdvisorResponse:', error)
            
            // Smarter fallback when Ollama unavailable
            const availableCourses = courses && courses.length > 0 ? courses : []
            const queryLower = query.toLowerCase()
            
            let text = ''
            let shouldShowCourses = true
            
            // Detect user intent
            if (queryLower.includes('kh√°c') || queryLower.includes('n√†o kh√°c')) {
                // User asking for other/different courses
                if (availableCourses.length === 1) {
                    text = `üìö Hi·ªán t·∫°i ch√∫ng t√¥i ch·ªâ c√≥ **1 kh√≥a h·ªçc**: JavaScript c∆° b·∫£n.\n\n`
                    text += `üéØ B·∫°n c√≥ th·ªÉ:\n`
                    text += `1. ƒêƒÉng k√Ω kh√≥a h·ªçc n√†y ƒë·ªÉ b·∫Øt ƒë·∫ßu\n`
                    text += `2. Cho t√¥i bi·∫øt lƒ©nh v·ª±c b·∫°n quan t√¢m (Web, Mobile, AI, Game, Data...)\n`
                    text += `3. Ch√∫ng t√¥i s·∫Ω th√™m kh√≥a h·ªçc ph√π h·ª£p s·ªõm\n\n`
                    text += `B·∫°n mu·ªën h·ªçc g√¨? üòä`
                } else {
                    text = `‚ú® D∆∞·ªõi ƒë√¢y l√† t·∫•t c·∫£ c√°c kh√≥a h·ªçc c√≥ s·∫µn:\n\n`
                }
            } else if (queryLower.includes('t∆∞ v·∫•n') || queryLower.includes('g·ª£i √Ω') || queryLower.includes('n√™n h·ªçc g√¨')) {
                // User asking for consultation/advice
                text = `üë®‚Äçüíº T√¥i s·∫µn s√†ng t∆∞ v·∫•n! ƒê·ªÉ gi√∫p b·∫°n t·ªët h∆°n, h√£y cho t√¥i bi·∫øt:\n\n`
                text += `üéØ **C√¢u h·ªèi ƒë·ªÉ t√¥i hi·ªÉu r√µ h∆°n:**\n`
                text += `1. B·∫°n mu·ªën h·ªçc v·ªÅ lƒ©nh v·ª±c g√¨? (Web, Mobile, Backend, Data, AI, Game, v.v.)\n`
                text += `2. Level hi·ªán t·∫°i c·ªßa b·∫°n? (Beginner, Intermediate, Advanced)\n`
                text += `3. B·∫°n c√≥ bao nhi√™u th·ªùi gian ƒë·ªÉ h·ªçc m·ªói tu·∫ßn?\n`
                text += `4. M·ª•c ti√™u h·ªçc t·∫≠p c·ªßa b·∫°n l√† g√¨? (T√¨m vi·ªác, n√¢ng cao k·ªπ nƒÉng, hobby...)\n\n`
                text += `Sau ƒë√≥ t√¥i s·∫Ω g·ª£i √Ω kh√≥a h·ªçc ph√π h·ª£p nh·∫•t! üí°`
                shouldShowCourses = false
            } else if (queryLower.length < 5 || /^(ok|ƒë∆∞·ª£c|g√¨|v√¢ng|okela|okie)$/i.test(queryLower)) {
                // Too short or acknowledgment
                text = `üëã B·∫°n mu·ªën bi·∫øt g√¨ th√™m? T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n\n`
                text += `- üîç T√¨m kh√≥a h·ªçc theo lƒ©nh v·ª±c\n`
                text += `- üìö G·ª£i √Ω kh√≥a h·ªçc ph√π h·ª£p v·ªõi level c·ªßa b·∫°n\n`
                text += `- ‚ùì Tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ kh√≥a h·ªçc\n\n`
                text += `H√£y n√≥i cho t√¥i bi·∫øt b·∫°n mu·ªën h·ªçc g√¨! üòä`
                shouldShowCourses = false
            } else {
                // General learning-related query
                text = `‚ú® B·∫°n quan t√¢m ƒë·∫øn: **${query}**\n\n`
            }
            
            // L·ªçc kh√≥a h·ªçc li√™n quan d·ª±a tr√™n intent
            const relevantCourses = shouldShowCourses
                ? availableCourses.filter((course) => this._isCourseRelevant(query, course))
                : []

            // N·∫øu kh√¥ng c√≥ kh√≥a li√™n quan, ƒë·ª´ng hi·ªÉn th·ªã danh s√°ch
            if (shouldShowCourses && relevantCourses.length === 0) {
                text += `Hi·ªán ch∆∞a c√≥ kh√≥a h·ªçc ph√π h·ª£p v·ªõi y√™u c·∫ßu n√†y. H√£y cho t√¥i bi·∫øt lƒ©nh v·ª±c/ng√¥n ng·ªØ b·∫°n mu·ªën h·ªçc (AI, Python, Web, v.v.) ƒë·ªÉ t√¥i g·ª£i √Ω ch√≠nh x√°c h∆°n!`
            }

            // Show courses if relevant
            if (shouldShowCourses && relevantCourses.length > 0) {
                text += `T√¨m th·∫•y ${relevantCourses.length} kh√≥a h·ªçc ph√π h·ª£p. Xem danh s√°ch b√™n d∆∞·ªõi üëá`
            }
            
            if (shouldShowCourses) {
                const sources = relevantCourses.slice(0, 4).map((course) => ({
                    type: 'course',
                    courseId: course.id,
                    courseTitle: course.title,
                    courseSlug: course.slug,
                    level: course.level,
                    price: course.price,
                    discountPrice: course.discountPrice,
                    rating: course.ratingAvg,
                    ratingCount: course.ratingCount,
                    enrolledCount: course.enrolledCount,
                    duration: course.durationHours,
                    lessons: course.totalLessons,
                    description: course.shortDescription,
                    thumbnail: course.thumbnailUrl,
                    instructor: course.instructor,
                }))

                return { text, sources }
            } else {
                return { text, sources: [] }
            }
        }
    }

    /**
     * Check if query is a greeting
     */
    _isGreeting(query) {
        if (!query || query.trim().length === 0) return true
        const greetings = /^(xin ch√†o|ch√†o|hello|hi|halo|hey|xin ch√†o b·∫°n|ch√†o b·∫°n|ch√†o em|xin k√≠nh ch√†o|t√¨nh h√¨nh|sao|sao r·ªìi|th·∫ø n√†o|kh·ªèe kh√¥ng|b·∫°n kh·ªèe kh√¥ng|alo|√™|∆°i)$/i
        return greetings.test(query.trim())
    }

    /**
     * Check if a course is relevant to the query
     */
    _isCourseRelevant(query, course) {
        if (!query || query.trim().length === 0) return false

        const haystack = `${course.title || ''} ${course.shortDescription || ''} ${course.description || ''} ${course.whatYouLearn || ''}`.toLowerCase()

        // Filter out generic Vietnamese stopwords so we only match on meaningful tech keywords
        const stopwords = new Set([
            'hoc', 'h·ªçc', 'muon', 'mu·ªën', 'toi', 't√¥i', 'ban', 'b·∫°n', 'lam', 'l√†m', 'viec', 'vi·ªác',
            'can', 'c·∫ßn', 'gi', 'g√¨', 'the', 'th·∫ø', 'n√†o', 'phu', 'ph√π', 'hop', 'h·ª£p', 'de', 'ƒë·ªÉ',
            've', 'v·ªÅ', 'khoa', 'kh√≥a', 'lop', 'l·ªõp', 'co', 'c√≥', 'trinh', 'tr√¨nh', 'lap', 'l·∫≠p',
            'co', 'c√≥', 'coi', 'xem', 'camon', 'c·∫£m', 'c·∫£m ∆°n', 'on', '∆°n'
        ])

        const allowShortKeywords = new Set(['ai', 'js', 'go', 'c', 'c++', 'c#', 'ui', 'ux', 'sql'])

        const keywords = query
            .toLowerCase()
            .split(/[^\p{L}\p{N}+#.]+/u)
            .filter((w) => w.length > 0)
            .filter((w) => (w.length >= 3 || allowShortKeywords.has(w)) && !stopwords.has(w))

        if (keywords.length === 0) return false

        return keywords.some((kw) => haystack.includes(kw))
    }
    generateTranscriptResponse(transcripts, query) {
        const topResult = transcripts[0]

        // Check if this is a full transcript request
        const isFullTranscript = topResult.isFullTranscript || false

        let text = `üìö **${isFullTranscript ? 'N·ªôi dung transcript c·ªßa b√†i h·ªçc' : 'T√¨m th·∫•y th√¥ng tin trong b√†i h·ªçc'}!**\n\n`
        text += `**B√†i:** ${topResult.lessonTitle}\n`
        text += `**Kh√≥a h·ªçc:** ${topResult.courseTitle}\n`

        if (topResult.timestamp && !isFullTranscript) {
            text += `**Th·ªùi ƒëi·ªÉm:** ${topResult.timestamp}\n\n`
        }

        if (isFullTranscript) {
            // Show full transcript content
            text += `**N·ªôi dung transcript (${topResult.totalSegments || 0} ƒëo·∫°n):**\n\n`
            text += `${topResult.excerpt}\n\n`
            if (topResult.text.length > 2000) {
                text += `\n*ƒê√¢y l√† ph·∫ßn ƒë·∫ßu c·ªßa transcript. ƒê·ªÉ xem ƒë·∫ßy ƒë·ªß, vui l√≤ng xem video b√†i h·ªçc.*\n\n`
            }
        } else {
            text += `**N·ªôi dung:**\n> ${topResult.excerpt}\n\n`
        }

        if (topResult.videoUrl && topResult.startTime) {
            text += `üé• **[Xem video t·∫°i ƒë√¢y](${topResult.videoUrl}?t=${Math.floor(topResult.startTime)})**\n\n`
        }

        // N·∫øu c√≥ nhi·ªÅu k·∫øt qu·∫£
        if (transcripts.length > 1 && !isFullTranscript) {
            text += `\nüìù **T√¨m th·∫•y th√™m ${transcripts.length - 1} ƒëo·∫°n li√™n quan kh√°c trong c√°c b√†i h·ªçc.**`
        }

        const sources = transcripts.slice(0, 3).map((t) => ({
            type: 'transcript',
            lessonId: t.lessonId,
            lessonTitle: t.lessonTitle,
            courseId: t.courseId,
            courseTitle: t.courseTitle,
            timestamp: t.timestamp,
            videoUrl: t.videoUrl,
            excerpt: t.excerpt,
        }))

        const suggestedActions = [
            {
                type: 'watch_video',
                label: 'Xem video',
                url: topResult.videoUrl,
                timestamp: topResult.startTime,
            },
            {
                type: 'view_lesson',
                label: 'Xem to√†n b·ªô b√†i h·ªçc',
                lessonId: topResult.lessonId,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi t√¨m th·∫•y trong lessons
     */
    generateLessonResponse(lessons, query, userContext) {
        const topLesson = lessons[0]

        let text = `üìñ **T√¨m th·∫•y b√†i h·ªçc li√™n quan!**\n\n`
        text += `**B√†i:** ${topLesson.title}\n`
        text += `**Kh√≥a h·ªçc:** ${topLesson.course.title}\n\n`

        if (topLesson.description) {
            text += `**M√¥ t·∫£:**\n${topLesson.description}\n\n`
        }

        // Check xem user ƒë√£ h·ªçc ch∆∞a
        const isCurrentCourse =
            userContext.currentCourse?.id === topLesson.courseId
        if (isCurrentCourse) {
            text += `üí° *B·∫°n ƒëang h·ªçc kh√≥a n√†y. H√£y ti·∫øp t·ª•c nh√©!*\n\n`
        }

        // List th√™m lessons n·∫øu c√≥
        if (lessons.length > 1) {
            text += `\n**C√°c b√†i h·ªçc li√™n quan kh√°c:**\n`
            lessons.slice(1, 4).forEach((lesson, index) => {
                text += `${index + 2}. ${lesson.title}\n`
            })
        }

        const sources = lessons.slice(0, 3).map((l) => ({
            type: 'lesson',
            lessonId: l.id,
            lessonTitle: l.title,
            courseId: l.courseId,
            courseTitle: l.course.title,
            description: l.description,
        }))

        const suggestedActions = [
            {
                type: 'view_lesson',
                label: 'Xem b√†i h·ªçc',
                lessonId: topLesson.id,
            },
            {
                type: 'view_course',
                label: 'Xem kh√≥a h·ªçc',
                courseId: topLesson.courseId,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi t√¨m th·∫•y trong courses
     */
    generateCourseResponse(courses, query) {
        const topCourse = courses[0]

        let text = `üéì **T√¨m th·∫•y kh√≥a h·ªçc li√™n quan!**\n\n`
        text += `**Kh√≥a h·ªçc:** ${topCourse.title}\n`
        text += `**C·∫•p ƒë·ªô:** ${topCourse.level}\n\n`

        if (topCourse.shortDescription) {
            text += `**M√¥ t·∫£:**\n${topCourse.shortDescription}\n\n`
        }

        if (topCourse.whatYouLearn) {
            text += `**B·∫°n s·∫Ω h·ªçc ƒë∆∞·ª£c:**\n${topCourse.whatYouLearn.substring(0, 200)}...\n\n`
        }

        if (courses.length > 1) {
            text += `\n**Kh√≥a h·ªçc li√™n quan kh√°c:**\n`
            courses.slice(1, 3).forEach((course, index) => {
                text += `${index + 2}. ${course.title} (${course.level})\n`
            })
        }

        const sources = courses.slice(0, 3).map((c) => ({
            type: 'course',
            courseId: c.id,
            courseTitle: c.title,
            level: c.level,
            description: c.shortDescription,
        }))

        const suggestedActions = [
            {
                type: 'view_course',
                label: 'Xem chi ti·∫øt kh√≥a h·ªçc',
                courseId: topCourse.id,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi h·ªèi v·ªÅ n·ªôi dung b√†i h·ªçc nh∆∞ng kh√¥ng c√≥ transcript
     */
    generateLessonContentResponse(currentLesson, query) {
        let text = `üìñ **Th√¥ng tin v·ªÅ b√†i h·ªçc:**\n\n`
        text += `**B√†i:** ${currentLesson.title || 'N/A'}\n\n`

        if (currentLesson.description) {
            text += `**M√¥ t·∫£:**\n${currentLesson.description}\n\n`
        }

        if (currentLesson.content) {
            const contentPreview =
                currentLesson.content.length > 500
                    ? currentLesson.content.substring(0, 500) + '...'
                    : currentLesson.content
            text += `**N·ªôi dung:**\n${contentPreview}\n\n`
        }

        text += `üí° *ƒê·ªÉ xem ƒë·∫ßy ƒë·ªß n·ªôi dung, vui l√≤ng xem video b√†i h·ªçc ho·∫∑c m√¥ t·∫£ chi ti·∫øt trong trang b√†i h·ªçc.*`

        return {
            text,
            sources: [
                {
                    type: 'lesson',
                    lessonId: currentLesson.id,
                    lessonTitle: currentLesson.title,
                },
            ],
            suggestedActions: [
                {
                    type: 'view_lesson',
                    label: 'Xem b√†i h·ªçc',
                    lessonId: currentLesson.id,
                },
            ],
        }
    }

    /**
     * Response khi kh√¥ng t√¨m th·∫•y g√¨
     */
    generateNoResultResponse(query, userContext) {
        let text = `üòî **Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ "${query}"**\n\n`

        // Check if query is asking about lesson content
        const isAskingAboutContent = /n·ªôi dung|content|b√†i h·ªçc|lesson/i.test(
            query
        )

        if (isAskingAboutContent && userContext.currentLesson) {
            text += `Trong b√†i h·ªçc: **${userContext.currentLesson.title}**, t√¥i kh√¥ng t√¨m th·∫•y n·ªôi dung li√™n quan. `
            text += `B·∫°n c√≥ th·ªÉ xem l·∫°i video b√†i h·ªçc ho·∫∑c m√¥ t·∫£ b√†i h·ªçc ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n\n`
            text += `**G·ª£i √Ω chuy·ªÉn t√πy ch·ªçn:**\n`
            text += `- Chuy·ªÉn sang "Kh√≥a h·ªçc" ƒë·ªÉ t√¨m trong to√†n b·ªô kh√≥a\n`
            text += `- Chuy·ªÉn sang "T·ªïng quan" ƒë·ªÉ ƒë·∫∑t c√¢u h·ªèi chung\n\n`
        }

        if (userContext.currentCourse) {
            text += `B·∫°n ƒëang h·ªçc kh√≥a: **${userContext.currentCourse.title}**\n\n`
            text += `**G·ª£i √Ω:**\n`
            text += `- Ki·ªÉm tra l·∫°i t·ª´ kh√≥a t√¨m ki·∫øm\n`
            text += `- Xem l·∫°i c√°c b√†i h·ªçc trong kh√≥a h·ªçc\n`
            if (isAskingAboutContent) {
                text += `- Xem video b√†i h·ªçc ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ n·ªôi dung\n`
            }
            text += `- Li√™n h·ªá gi·∫£ng vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n`
        } else {
            text += `**G·ª£i √Ω:**\n`
            text += `- H√£y enroll v√†o m·ªôt kh√≥a h·ªçc ƒë·ªÉ b·∫Øt ƒë·∫ßu h·ªçc\n`
            text += `- T√¨m ki·∫øm kh√≥a h·ªçc ph√π h·ª£p v·ªõi b·∫°n\n`
        }

        return {
            text,
            sources: [],
            suggestedActions: [
                {
                    type: 'browse_courses',
                    label: 'Xem c√°c kh√≥a h·ªçc',
                },
            ],
        }
    }

    /**
     * General fallback for non-course mode (friendly conversational replies)
     */
    generateGeneralFallbackResponse(query) {
        const greetingRegex = /(xin ch√†o|ch√†o|hello|hi|hey|c√≥ ·ªü ƒë√≥|are you there)/i
        if (greetingRegex.test(query)) {
            const text = `Ch√†o b·∫°n! M√¨nh l√† Gia s∆∞ AI ‚Äî m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n nh·ªØng g√¨ v·ªÅ l·∫≠p tr√¨nh ho·∫∑c h·ªçc t·∫≠p h√¥m nay?`
            return { text, sources: [], suggestedActions: [] }
        }

        const text = `M√¨nh c√≥ th·ªÉ gi√∫p tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ l·∫≠p tr√¨nh, kh√≥a h·ªçc v√† h·ªçc t·∫≠p. B·∫°n mu·ªën h·ªèi ƒëi·ªÅu g√¨ c·ª• th·ªÉ?`
        return { text, sources: [], suggestedActions: [] }
    }

    /**
     * Get messages trong conversation (optimized: combine verification with count)
     */
    async getMessages(conversationId, userId, page = 1, limit = 50, order = 'asc') {
        try {
            // Verify conversation access (allows both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            const [messages, total] = await Promise.all([
                prisma.chatMessage.findMany({
                    where: { conversationId },
                    orderBy: { createdAt: order === 'desc' ? 'desc' : 'asc' },
                    skip: (page - 1) * limit,
                    take: limit,
                    select: {
                        id: true,
                        senderType: true,
                        message: true,
                        messageType: true,
                        metadata: true,
                        isHelpful: true,
                        feedbackText: true,
                        createdAt: true,
                    },
                }),
                prisma.chatMessage.count({
                    where: { conversationId },
                }),
            ])

            return {
                messages,
                pagination: {
                    page,
                    limit,
                    total,
                    totalPages: Math.ceil(total / limit),
                },
            }
        } catch (error) {
            logger.error('Error getting messages:', error)
            throw error
        }
    }

    /**
     * Feedback message (helpful/not helpful)
     */
    async feedbackMessage(messageId, userId, isHelpful, feedbackText = null) {
        try {
            // Verify message belongs to user's conversation
            const message = await prisma.chatMessage.findFirst({
                where: {
                    id: messageId,
                    conversation: {
                        userId,
                    },
                },
            })

            if (!message) {
                const error = new Error('Message not found or access denied')
                error.statusCode = 404
                throw error
            }

            const updated = await prisma.chatMessage.update({
                where: { id: messageId },
                data: {
                    isHelpful,
                    feedbackText,
                },
            })

            logger.info(
                `Feedback submitted for message ${messageId}: ${isHelpful ? 'helpful' : 'not helpful'}`
            )

            return updated
        } catch (error) {
            logger.error('Error submitting feedback:', error)
            throw error
        }
    }

    /**
     * Get user's conversations
     */
    async getConversations(userId, options = {}) {
        try {
            const { isArchived = false, page = 1, limit = 20, mode } = options

            const where = {
                userId,
                isArchived,
            }

            // Add mode filter if provided
            if (mode) {
                where.mode = mode
            }

            const conversations = await prisma.conversation.findMany({
                where,
                orderBy: { lastMessageAt: 'desc' },
                skip: (page - 1) * limit,
                take: limit,
                include: {
                    course: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                            thumbnailUrl: true,
                        },
                    },
                    lesson: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                    _count: {
                        select: { messages: true },
                    },
                    messages: {
                        take: 1,
                        orderBy: { createdAt: 'desc' },
                        select: {
                            message: true,
                            senderType: true,
                        },
                    },
                },
            })

            // Map to include lastMessage in a cleaner format
            const conversationsWithLastMessage = conversations.map(conv => ({
                ...conv,
                lastMessage: conv.messages?.[0]?.message || null,
                lastMessageSender: conv.messages?.[0]?.senderType || null,
            }))

            const total = await prisma.conversation.count({ where })

            return {
                conversations: conversationsWithLastMessage,
                pagination: {
                    page,
                    limit,
                    total,
                    totalPages: Math.ceil(total / limit),
                },
            }
        } catch (error) {
            logger.error('Error getting conversations:', error)
            throw error
        }
    }

    /**
     * Archive conversation
     */
    async archiveConversation(conversationId, userId) {
        try {
            // Verify conversation access (only allow deletion of conversations owned by user, not public advisor conversations)
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can archive their conversation
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can archive')
                error.statusCode = 403
                throw error
            }

            await prisma.conversation.update({
                where: { id: conversationId },
                data: { isArchived: true, isActive: false },
            })

            logger.info(`Archived conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error archiving conversation:', error)
            throw error
        }
    }

    /**
     * Delete conversation
     */
    async deleteConversation(conversationId, userId) {
        try {
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can delete their conversation (advisor conversations are temporary and read-only)
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can delete')
                error.statusCode = 403
                throw error
            }

            // Cascade delete messages (handled by Prisma)
            await prisma.conversation.delete({
                where: { id: conversationId },
            })

            logger.info(`Deleted conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error deleting conversation:', error)
            throw error
        }
    }

    /**
     * Update conversation
     */
    async updateConversation(conversationId, userId, data) {
        try {
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can update their conversation (advisor conversations are read-only)
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can update')
                error.statusCode = 403
                throw error
            }

            const updated = await prisma.conversation.update({
                where: { id: conversationId },
                data: {
                    title: data.title,
                },
            })

            logger.info(`Updated conversation ${conversationId}`)
            return updated
        } catch (error) {
            logger.error('Error updating conversation:', error)
            throw error
        }
    }
}

export default new AIChatService()
