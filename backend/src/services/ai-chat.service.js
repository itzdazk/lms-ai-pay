// src/services/ai-chat.service.js
import { prisma } from '../config/database.config.js'
import knowledgeBaseService from './knowledge-base.service.js'
import ollamaService from './ollama.service.js'
import logger from '../config/logger.config.js'
import config from '../config/app.config.js'
import { HTTP_STATUS, AI_INTERACTION_TYPES } from '../config/constants.js'

class AIChatService {
    /**
     * Helper: Verify conversation access
     * - If conversation.userId is null: public advisor conversation, allow access
     * - If conversation.userId is set: must match current userId
     * @returns {Promise<Object>} conversation object
     * @throws Error if conversation not found or access denied
     */
    async verifyConversationAccess(conversationId, userId) {
        const conversation = await prisma.conversation.findUnique({
            where: { id: conversationId }
        })

        if (!conversation) {
            const error = new Error('Conversation not found')
            error.statusCode = 404
            throw error
        }

        // Public advisor conversation (userId = null) - allow access
        if (conversation.userId === null) {
            return conversation
        }

        // Private conversation - must match current user
        if (conversation.userId !== userId) {
            const error = new Error('Access denied: This conversation belongs to another user')
            error.statusCode = 403
            throw error
        }

        return conversation
    }
    /**
     * T·∫°o conversation m·ªõi
     */
    async createConversation(userId, data = {}) {
        try {
            const { courseId, lessonId, title, mode = 'general' } = data

            // Validate courseId and lessonId exist (if provided)
            let validCourseId = null
            let validLessonId = null
            let course = null
            let lesson = null

            if (courseId) {
                course = await prisma.course.findUnique({
                    where: { id: courseId },
                    select: { id: true, title: true },
                })
                if (course) {
                    validCourseId = courseId
                } else {
                    const error = new Error('Course not found')
                    error.statusCode = HTTP_STATUS.NOT_FOUND
                    throw error
                }
            }

            if (lessonId) {
                lesson = await prisma.lesson.findUnique({
                    where: { id: lessonId },
                    select: { id: true, title: true, courseId: true },
                })
                if (lesson) {
                    validLessonId = lessonId
                    // If lesson exists but courseId doesn't match, use lesson's courseId
                    if (!validCourseId && lesson.courseId) {
                        const lessonCourse = await prisma.course.findUnique({
                            where: { id: lesson.courseId },
                            select: { id: true, title: true },
                        })
                        if (lessonCourse) {
                            validCourseId = lesson.courseId
                            course = lessonCourse
                        }
                    }
                } else {
                    const error = new Error('Lesson not found')
                    error.statusCode = HTTP_STATUS.NOT_FOUND
                    throw error
                }
            }

            // Auto-generate title n·∫øu kh√¥ng c√≥
            let conversationTitle = title

            if (!conversationTitle) {
                if (course) {
                    conversationTitle = `Chat v·ªÅ ${course.title}`
                } else if (lesson) {
                    conversationTitle = `Chat v·ªÅ ${lesson.title}`
                } else {
                    conversationTitle = 'Tr√≤ chuy·ªán chung'
                }
            }

            // Determine context type
            let contextType = AI_INTERACTION_TYPES.GENERAL_CHAT
            if (validLessonId) {
                contextType = AI_INTERACTION_TYPES.LESSON_HELP
            } else if (validCourseId) {
                contextType = AI_INTERACTION_TYPES.COURSE_OVERVIEW
            }

            const conversation = await prisma.conversation.create({
                data: {
                    userId,
                    courseId: validCourseId,
                    lessonId: validLessonId,
                    title: conversationTitle,
                    contextType,
                    mode, // Add mode from data or default to 'general'
                    aiModel: config.OLLAMA_MODEL || 'llama3.1:latest', // Use Ollama model name
                    isActive: true,
                    isArchived: false,
                    lastMessageAt: new Date(),
                },
                include: {
                    course: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                    lesson: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                },
            })

            // Create an initial assistant greeting message so AI is the first sender
            try {
                const greetingText = (() => {
                    if (lesson) {
                        return `Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p v·ªÅ b√†i h·ªçc "${lesson.title}" v√† h·ªó tr·ª£ h·ªçc t·∫≠p. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?`
                    }
                    if (course) {
                        return `Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p v·ªÅ kh√≥a h·ªçc "${course.title}" v√† h·ªó tr·ª£ h·ªçc t·∫≠p. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?`
                    }
                    return 'Xin ch√†o! T√¥i l√† Gia s∆∞ AI. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p th·∫Øc m·∫Øc, h·ªó tr·ª£ h·ªçc t·∫≠p v√† t∆∞ v·∫•n l·ªô tr√¨nh. B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ kh√¥ng?'
                })()

                await prisma.chatMessage.create({
                    data: {
                        conversationId: conversation.id,
                        senderType: 'ai',
                        message: greetingText,
                        messageType: 'text',
                    },
                })

                // Update lastMessageAt to the greeting timestamp
                await prisma.conversation.update({
                    where: { id: conversation.id },
                    data: { lastMessageAt: new Date() },
                })
            } catch (greetErr) {
                logger.warn('Failed to create initial AI greeting message:', greetErr)
            }

            logger.info(
                `Created conversation ${conversation.id} for user ${userId}`
            )
            return conversation
        } catch (error) {
            logger.error('Error creating conversation:', error)
            throw error
        }
    }

    /**
     * G·ª≠i message v√† nh·∫≠n response
     */
    async sendMessage(userId, conversationId, messageText, mode = 'course', lessonId = null) {
        try {
            // 1. Verify conversation access (handles both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            // 2. L∆∞u message c·ªßa user
            const userMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'user',
                    message: messageText,
                    messageType: 'text',
                },
            })

            // 3. Build context t·ª´ knowledge base (with timing)
            const contextStartTime = Date.now()
            // Pass mode and lessonId so knowledgeBaseService can use dynamic lessonId
            const context = await knowledgeBaseService.buildContext(
                userId,
                messageText,
                conversationId,
                { mode, dynamicLessonId: lessonId }
            )
            const contextDuration = Date.now() - contextStartTime
            logger.debug(`Knowledge base context built in ${contextDuration}ms`)

            // 4. Get conversation history for context (use knowledge base service)
            const conversationHistory =
                await knowledgeBaseService.getConversationHistory(
                    conversationId,
                    10
                )

            // 5. Generate response using Ollama (with improved fallback to template)
            let responseData
            let usedOllama = false
            let fallbackReason = null
            const responseStartTime = Date.now()

            try {
                // Try Ollama first (even if no knowledge base results)
                if (ollamaService.enabled) {
                    // Quick health check (cached, should be fast)
                    const healthCheckStart = Date.now()
                    const isOllamaAvailable = await ollamaService.checkHealth()
                    const healthCheckDuration = Date.now() - healthCheckStart

                    if (isOllamaAvailable) {
                        try {
                            // Set timeout for Ollama generation
                            const generationTimeout = 120000 // 120s
                            const timeoutPromise = new Promise((_, reject) => {
                                setTimeout(
                                    () =>
                                        reject(
                                            new Error(
                                                'Ollama generation timeout'
                                            )
                                        ),
                                    generationTimeout
                                )
                            })

                            const generationPromise =
                                this.generateOllamaResponse(
                                    messageText,
                                    conversationHistory,
                                    context,
                                    mode
                                )

                            responseData = await Promise.race([
                                generationPromise,
                                timeoutPromise,
                            ])
                            usedOllama = true
                            const responseDuration =
                                Date.now() - responseStartTime
                            logger.info(
                                `Ollama response generated in ${responseDuration}ms ` +
                                    `(health check: ${healthCheckDuration}ms, ` +
                                    `hasKnowledgeBase: ${context.searchResults.totalResults > 0})`
                            )
                        } catch (ollamaError) {
                            const errorDuration = Date.now() - responseStartTime
                            fallbackReason =
                                ollamaError.message || 'Unknown error'

                            // Log error with context
                            if (ollamaError.message?.includes('timeout')) {
                                logger.warn(
                                    `Ollama generation timeout after ${errorDuration}ms, falling back to template`
                                )
                            } else {
                                logger.error(
                                    `Ollama generation failed after ${errorDuration}ms, falling back to template:`,
                                    ollamaError.message,
                                    ollamaError.stack
                                )
                            }

                            // Fallback to template with error context
                            responseData = this.generateTemplateResponse(
                                context,
                                messageText,
                                { error: fallbackReason }
                            )
                        }
                    } else {
                        const checkDuration = Date.now() - responseStartTime
                        fallbackReason = 'Ollama service unavailable'
                        logger.warn(
                            `Ollama not available (checked in ${checkDuration}ms), falling back to template response`
                        )
                        responseData = this.generateTemplateResponse(
                            context,
                            messageText,
                            { reason: fallbackReason }
                        )
                    }
                } else {
                    // Ollama disabled, use template
                    fallbackReason = 'Ollama disabled in config'
                    logger.debug('Ollama disabled, using template response')
                    responseData = this.generateTemplateResponse(
                        context,
                        messageText,
                        { reason: fallbackReason }
                    )
                }
            } catch (error) {
                // Catch-all error handler
                fallbackReason = error.message || 'Unexpected error'
                logger.error(
                    `Error generating response (${fallbackReason}), using template fallback:`,
                    error.message,
                    error.stack
                )
                // Fallback to template response
                responseData = this.generateTemplateResponse(
                    context,
                    messageText,
                    { error: fallbackReason }
                )
            }

            // 6. L∆∞u AI response
            const aiMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'ai',
                    message: responseData.text,
                    messageType: 'text',
                    metadata: {
                        sources: responseData.sources,
                        suggestedActions: responseData.suggestedActions,
                        usedOllama,
                        fallbackReason: fallbackReason || null,
                        responseTime: Date.now() - responseStartTime,
                        mode,
                    },
                },
            })

            // 7. Update conversation last message time
            await prisma.conversation.update({
                where: { id: conversationId },
                data: { lastMessageAt: new Date() },
            })

            logger.info(`Sent message in conversation ${conversationId}`)

            return {
                userMessage,
                aiMessage,
                context: {
                    hasResults: context.searchResults.totalResults > 0,
                    totalResults: context.searchResults.totalResults,
                },
            }
        } catch (error) {
            logger.error('Error sending message:', error)
            throw error
        }
    }

    /**
     * Send message with streaming response (for better UX)
     */
    async sendMessageStream(userId, conversationId, messageText, mode = 'course', onChunk, lessonId = null) {
        try {
            // 1. Verify conversation access (handles both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            // 2. L∆∞u message c·ªßa user
            const userMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'user',
                    message: messageText,
                    messageType: 'text',
                },
            })

            // Send user message chunk
            onChunk({
                type: 'user_message',
                data: userMessage,
            })

            // 3. Build context t·ª´ knowledge base (fast, with cache)
            const context = await knowledgeBaseService.buildContext(
                userId,
                messageText,
                conversationId,
                { mode, dynamicLessonId: lessonId }
            )

            // 4. Get conversation history
            const conversationHistory =
                await knowledgeBaseService.getConversationHistory(
                    conversationId,
                    5 // Reduced from 10 to speed up
                )

            // 5. Generate streaming response using Ollama
            let fullResponse = ''
            let sources = []
            let suggestedActions = []
            let streamingError = null
            let usedOllama = false

            try {
                if (ollamaService.enabled) {
                    const isOllamaAvailable = await ollamaService.checkHealth()
                    if (isOllamaAvailable) {
                        // Build system prompt
                        const systemPrompt =
                            ollamaService.buildSystemPrompt(context, mode)

                        // Stream response from Ollama
                        try {
                            for await (const chunk of ollamaService.generateResponseStream(
                                messageText,
                                conversationHistory,
                                systemPrompt
                            )) {
                                fullResponse += chunk
                                onChunk({
                                    type: 'ai_chunk',
                                    chunk: chunk,
                                    accumulated: fullResponse,
                                })
                            }

                            usedOllama = true

                            // Extract sources and actions from context
                            if (context.searchResults.transcripts.length > 0) {
                                sources.push(
                                    ...context.searchResults.transcripts
                                        .slice(0, 3)
                                        .map((t) => ({
                                            type: 'transcript',
                                            lessonId: t.lessonId,
                                            lessonTitle: t.lessonTitle,
                                            courseId: t.courseId,
                                            courseTitle: t.courseTitle,
                                            timestamp: t.timestamp,
                                            videoUrl: t.videoUrl,
                                            excerpt: t.excerpt,
                                        }))
                                )
                            }
                            if (context.searchResults.lessons.length > 0) {
                                sources.push(
                                    ...context.searchResults.lessons
                                        .slice(0, 2)
                                        .map((l) => ({
                                            type: 'lesson',
                                            lessonId: l.id,
                                            lessonTitle: l.title,
                                            courseId: l.courseId,
                                            courseTitle: l.course?.title,
                                        }))
                                )
                            }

                            // Build suggested actions
                            if (context.searchResults.transcripts.length > 0) {
                                const topTranscript =
                                    context.searchResults.transcripts[0]
                                suggestedActions.push({
                                    type: 'watch_video',
                                    label: 'Xem video',
                                    url: topTranscript.videoUrl,
                                    timestamp: topTranscript.startTime,
                                })
                            }
                            if (context.searchResults.lessons.length > 0) {
                                suggestedActions.push({
                                    type: 'view_lesson',
                                    label: 'Xem b√†i h·ªçc',
                                    lessonId:
                                        context.searchResults.lessons[0].id,
                                })
                            }
                        } catch (streamError) {
                            streamingError = streamError
                            logger.error(
                                'Error during Ollama streaming:',
                                streamError
                            )
                            // Continue to fallback
                        }
                    }

                    // Fallback to template if Ollama not available or streaming failed
                    if (
                        !isOllamaAvailable ||
                        streamingError ||
                        !fullResponse.trim()
                    ) {
                        logger.warn(
                            'Falling back to template response (Ollama unavailable or streaming failed)'
                        )
                        const templateResponse = this.generateTemplateResponse(
                            context,
                            messageText
                        )
                        fullResponse = templateResponse.text
                        sources = templateResponse.sources || []
                        suggestedActions =
                            templateResponse.suggestedActions || []

                        // Send as single chunk if not already streaming
                        if (
                            !fullResponse.includes('\n') ||
                            fullResponse.length < 100
                        ) {
                            onChunk({
                                type: 'ai_chunk',
                                chunk: fullResponse,
                                accumulated: fullResponse,
                            })
                        }
                    }
                } else {
                    // Ollama disabled, use template
                    const templateResponse = this.generateTemplateResponse(
                        context,
                        messageText
                    )
                    fullResponse = templateResponse.text
                    sources = templateResponse.sources || []
                    suggestedActions = templateResponse.suggestedActions || []
                    onChunk({
                        type: 'ai_chunk',
                        chunk: fullResponse,
                        accumulated: fullResponse,
                    })
                }
            } catch (error) {
                logger.error('Error in streaming response:', error)
                // Fallback to template
                const templateResponse = this.generateTemplateResponse(
                    context,
                    messageText
                )
                fullResponse = templateResponse.text
                sources = templateResponse.sources || []
                suggestedActions = templateResponse.suggestedActions || []
                onChunk({
                    type: 'ai_chunk',
                    chunk: fullResponse,
                    accumulated: fullResponse,
                })
            }

            // 6. L∆∞u AI response
            const aiMessage = await prisma.chatMessage.create({
                data: {
                    conversationId,
                    senderType: 'ai',
                    message: fullResponse,
                    messageType: 'text',
                    metadata: {
                        sources,
                        suggestedActions,
                        usedOllama,
                        fallbackReason: streamingError ? (streamingError.message || String(streamingError)) : null,
                        responseTime: Date.now() - responseStartTime,
                        mode,
                    },
                },
            })

            // 7. Update conversation
            await prisma.conversation.update({
                where: { id: conversationId },
                data: { lastMessageAt: new Date() },
            })

            // Send final message
            onChunk({
                type: 'ai_message',
                data: aiMessage,
            })

            logger.info(`Streamed message in conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error streaming message:', error)
            throw error
        }
    }

    /**
     * Generate response using Ollama with knowledge base context
     */
    async generateOllamaResponse(messageText, conversationHistory, context, mode = 'course') {
        try {
            // Build system prompt with knowledge base
            const systemPrompt = ollamaService.buildSystemPrompt(context, mode)

            // Generate response from Ollama
            const aiResponse = await ollamaService.generateResponse(
                messageText,
                conversationHistory,
                systemPrompt
            )

            // Extract sources from context
            const sources = []
            if (context.searchResults.transcripts.length > 0) {
                sources.push(
                    ...context.searchResults.transcripts
                        .slice(0, 3)
                        .map((t) => ({
                            type: 'transcript',
                            lessonId: t.lessonId,
                            lessonTitle: t.lessonTitle,
                            courseId: t.courseId,
                            courseTitle: t.courseTitle,
                            timestamp: t.timestamp,
                            videoUrl: t.videoUrl,
                            excerpt: t.excerpt,
                        }))
                )
            }
            if (context.searchResults.lessons.length > 0) {
                sources.push(
                    ...context.searchResults.lessons.slice(0, 2).map((l) => ({
                        type: 'lesson',
                        lessonId: l.id,
                        lessonTitle: l.title,
                        courseId: l.courseId,
                        courseTitle: l.course.title,
                    }))
                )
            }

            // Build suggested actions based on search results
            const suggestedActions = []
            if (context.searchResults.transcripts.length > 0) {
                const topTranscript = context.searchResults.transcripts[0]
                suggestedActions.push({
                    type: 'watch_video',
                    label: 'Xem video',
                    url: topTranscript.videoUrl,
                    timestamp: topTranscript.startTime,
                })
            }
            if (context.searchResults.lessons.length > 0) {
                suggestedActions.push({
                    type: 'view_lesson',
                    label: 'Xem b√†i h·ªçc',
                    lessonId: context.searchResults.lessons[0].id,
                })
            }

            // Prefix clarity for lesson mode: always state which lesson/course
            let prefix = ''
            if (mode === 'course') {
                const lessonTitle =
                    context?.searchResults?.transcripts?.[0]?.lessonTitle ||
                    context?.userContext?.currentLesson?.title ||
                    null
                const courseTitle =
                    context?.searchResults?.transcripts?.[0]?.courseTitle ||
                    context?.userContext?.currentCourse?.title ||
                    null

                if (lessonTitle || courseTitle) {
                    prefix += `üîé Ng·ªØ c·∫£nh: B√†i h·ªçc${lessonTitle ? ` "${lessonTitle}"` : ''}${courseTitle ? ` trong kh√≥a "${courseTitle}"` : ''}.\n\n`
                }
                // If nothing found in this lesson, state it clearly and suggest options
                const hasResults = (context?.searchResults?.totalResults || 0) > 0
                if (!hasResults && lessonTitle) {
                    prefix += `‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung li√™n quan trong b√†i h·ªçc n√†y. B·∫°n c√≥ th·ªÉ:\n- Chuy·ªÉn sang t√πy ch·ªçn "T·ªïng quan" ƒë·ªÉ h·ªèi chung\n- Ho·∫∑c m√¥ t·∫£ chi ti·∫øt h∆°n c√¢u h·ªèi\n\n`
                }
            }

            return {
                text: prefix + aiResponse,
                sources: sources.slice(0, 5), // Limit to 5 sources
                suggestedActions,
            }
        } catch (error) {
            logger.error('Error in generateOllamaResponse:', error)
            throw error
        }
    }

    // getConversationHistory moved to knowledgeBaseService to avoid duplication

    /**
     * Generate template response (fallback method)
     * @param {Object} context - Knowledge base context
     * @param {string} query - User query
     * @param {Object} options - Additional options (error, reason)
     */
    generateTemplateResponse(context, query, options = {}) {
        const { searchResults, userContext, mode } = context;

        // If in general mode, return a friendly conversational fallback
        if (mode === 'general') {
            return this.generateGeneralFallbackResponse(query);
        }

        // CASE 1: T√¨m th·∫•y trong TRANSCRIPT (Best case!)
        if (searchResults.transcripts.length > 0) {
            return this.generateTranscriptResponse(
                searchResults.transcripts,
                query
            );
        }

        // CASE 2: T√¨m th·∫•y trong LESSONS
        if (searchResults.lessons.length > 0) {
            return this.generateLessonResponse(
                searchResults.lessons,
                query,
                userContext
            );
        }

        // CASE 3: T√¨m th·∫•y trong COURSES (Advisor mode: custom advisor-style response)
        if (searchResults.courses.length > 0) {
            if (mode === 'advisor') {
                // Custom advisor-style response for course recommendations
                const topCourses = searchResults.courses.slice(0, 8);
                let text = `ü§ñ **G·ª£i √Ω kh√≥a h·ªçc ph√π h·ª£p cho b·∫°n:**\n\n`;
                topCourses.forEach((course, idx) => {
                    text += `${idx + 1}. **${course.title}**`;
                    if (course.level) text += ` _(C·∫•p ƒë·ªô: ${course.level})_`;
                    text += `\n`;
                    if (course.shortDescription) text += `   - ${course.shortDescription}\n`;
                });
                text += `\nB·∫°n c√≥ th·ªÉ nh·∫•n v√†o t·ª´ng kh√≥a h·ªçc ƒë·ªÉ xem chi ti·∫øt ho·∫∑c ƒëƒÉng k√Ω h·ªçc ngay!`;

                const sources = topCourses.map((c) => ({
                    type: 'course',
                    courseId: c.id,
                    courseTitle: c.title,
                    level: c.level,
                    description: c.shortDescription,
                }));

                const suggestedActions = topCourses.map((c) => ({
                    type: 'view_course',
                    label: `Xem kh√≥a "${c.title}"`,
                    courseId: c.id,
                }));

                return { text, sources, suggestedActions };
            } else {
                return this.generateCourseResponse(searchResults.courses, query);
            }
        }

        // CASE 4: Kh√¥ng t√¨m th·∫•y g√¨ - nh∆∞ng n·∫øu ƒëang h·ªèi v·ªÅ n·ªôi dung b√†i h·ªçc v√† c√≥ currentLesson,
        // th√¨ tr·∫£ v·ªÅ th√¥ng tin t·ª´ lesson content/description
        const isAskingAboutContent =
            /n·ªôi dung|content|b√†i h·ªçc n√†y|lesson/i.test(query);
        if (isAskingAboutContent && userContext.currentLesson) {
            return this.generateLessonContentResponse(
                userContext.currentLesson,
                query
            );
        }

        // CASE 5: Kh√¥ng t√¨m th·∫•y g√¨
        return this.generateNoResultResponse(query, userContext);
    }

    /**
     * Response khi t√¨m th·∫•y trong transcript
     */
    generateTranscriptResponse(transcripts, query) {
        const topResult = transcripts[0]

        // Check if this is a full transcript request
        const isFullTranscript = topResult.isFullTranscript || false

        let text = `üìö **${isFullTranscript ? 'N·ªôi dung transcript c·ªßa b√†i h·ªçc' : 'T√¨m th·∫•y th√¥ng tin trong b√†i h·ªçc'}!**\n\n`
        text += `**B√†i:** ${topResult.lessonTitle}\n`
        text += `**Kh√≥a h·ªçc:** ${topResult.courseTitle}\n`

        if (topResult.timestamp && !isFullTranscript) {
            text += `**Th·ªùi ƒëi·ªÉm:** ${topResult.timestamp}\n\n`
        }

        if (isFullTranscript) {
            // Show full transcript content
            text += `**N·ªôi dung transcript (${topResult.totalSegments || 0} ƒëo·∫°n):**\n\n`
            text += `${topResult.excerpt}\n\n`
            if (topResult.text.length > 2000) {
                text += `\n*ƒê√¢y l√† ph·∫ßn ƒë·∫ßu c·ªßa transcript. ƒê·ªÉ xem ƒë·∫ßy ƒë·ªß, vui l√≤ng xem video b√†i h·ªçc.*\n\n`
            }
        } else {
            text += `**N·ªôi dung:**\n> ${topResult.excerpt}\n\n`
        }

        if (topResult.videoUrl && topResult.startTime) {
            text += `üé• **[Xem video t·∫°i ƒë√¢y](${topResult.videoUrl}?t=${Math.floor(topResult.startTime)})**\n\n`
        }

        // N·∫øu c√≥ nhi·ªÅu k·∫øt qu·∫£
        if (transcripts.length > 1 && !isFullTranscript) {
            text += `\nüìù **T√¨m th·∫•y th√™m ${transcripts.length - 1} ƒëo·∫°n li√™n quan kh√°c trong c√°c b√†i h·ªçc.**`
        }

        const sources = transcripts.slice(0, 3).map((t) => ({
            type: 'transcript',
            lessonId: t.lessonId,
            lessonTitle: t.lessonTitle,
            courseId: t.courseId,
            courseTitle: t.courseTitle,
            timestamp: t.timestamp,
            videoUrl: t.videoUrl,
            excerpt: t.excerpt,
        }))

        const suggestedActions = [
            {
                type: 'watch_video',
                label: 'Xem video',
                url: topResult.videoUrl,
                timestamp: topResult.startTime,
            },
            {
                type: 'view_lesson',
                label: 'Xem to√†n b·ªô b√†i h·ªçc',
                lessonId: topResult.lessonId,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi t√¨m th·∫•y trong lessons
     */
    generateLessonResponse(lessons, query, userContext) {
        const topLesson = lessons[0]

        let text = `üìñ **T√¨m th·∫•y b√†i h·ªçc li√™n quan!**\n\n`
        text += `**B√†i:** ${topLesson.title}\n`
        text += `**Kh√≥a h·ªçc:** ${topLesson.course.title}\n\n`

        if (topLesson.description) {
            text += `**M√¥ t·∫£:**\n${topLesson.description}\n\n`
        }

        // Check xem user ƒë√£ h·ªçc ch∆∞a
        const isCurrentCourse =
            userContext.currentCourse?.id === topLesson.courseId
        if (isCurrentCourse) {
            text += `üí° *B·∫°n ƒëang h·ªçc kh√≥a n√†y. H√£y ti·∫øp t·ª•c nh√©!*\n\n`
        }

        // List th√™m lessons n·∫øu c√≥
        if (lessons.length > 1) {
            text += `\n**C√°c b√†i h·ªçc li√™n quan kh√°c:**\n`
            lessons.slice(1, 4).forEach((lesson, index) => {
                text += `${index + 2}. ${lesson.title}\n`
            })
        }

        const sources = lessons.slice(0, 3).map((l) => ({
            type: 'lesson',
            lessonId: l.id,
            lessonTitle: l.title,
            courseId: l.courseId,
            courseTitle: l.course.title,
            description: l.description,
        }))

        const suggestedActions = [
            {
                type: 'view_lesson',
                label: 'Xem b√†i h·ªçc',
                lessonId: topLesson.id,
            },
            {
                type: 'view_course',
                label: 'Xem kh√≥a h·ªçc',
                courseId: topLesson.courseId,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi t√¨m th·∫•y trong courses
     */
    generateCourseResponse(courses, query) {
        const topCourse = courses[0]

        let text = `üéì **T√¨m th·∫•y kh√≥a h·ªçc li√™n quan!**\n\n`
        text += `**Kh√≥a h·ªçc:** ${topCourse.title}\n`
        text += `**C·∫•p ƒë·ªô:** ${topCourse.level}\n\n`

        if (topCourse.shortDescription) {
            text += `**M√¥ t·∫£:**\n${topCourse.shortDescription}\n\n`
        }

        if (topCourse.whatYouLearn) {
            text += `**B·∫°n s·∫Ω h·ªçc ƒë∆∞·ª£c:**\n${topCourse.whatYouLearn.substring(0, 200)}...\n\n`
        }

        if (courses.length > 1) {
            text += `\n**Kh√≥a h·ªçc li√™n quan kh√°c:**\n`
            courses.slice(1, 3).forEach((course, index) => {
                text += `${index + 2}. ${course.title} (${course.level})\n`
            })
        }

        const sources = courses.slice(0, 3).map((c) => ({
            type: 'course',
            courseId: c.id,
            courseTitle: c.title,
            level: c.level,
            description: c.shortDescription,
        }))

        const suggestedActions = [
            {
                type: 'view_course',
                label: 'Xem chi ti·∫øt kh√≥a h·ªçc',
                courseId: topCourse.id,
            },
        ]

        return { text, sources, suggestedActions }
    }

    /**
     * Response khi h·ªèi v·ªÅ n·ªôi dung b√†i h·ªçc nh∆∞ng kh√¥ng c√≥ transcript
     */
    generateLessonContentResponse(currentLesson, query) {
        let text = `üìñ **Th√¥ng tin v·ªÅ b√†i h·ªçc:**\n\n`
        text += `**B√†i:** ${currentLesson.title || 'N/A'}\n\n`

        if (currentLesson.description) {
            text += `**M√¥ t·∫£:**\n${currentLesson.description}\n\n`
        }

        if (currentLesson.content) {
            const contentPreview =
                currentLesson.content.length > 500
                    ? currentLesson.content.substring(0, 500) + '...'
                    : currentLesson.content
            text += `**N·ªôi dung:**\n${contentPreview}\n\n`
        }

        text += `üí° *ƒê·ªÉ xem ƒë·∫ßy ƒë·ªß n·ªôi dung, vui l√≤ng xem video b√†i h·ªçc ho·∫∑c m√¥ t·∫£ chi ti·∫øt trong trang b√†i h·ªçc.*`

        return {
            text,
            sources: [
                {
                    type: 'lesson',
                    lessonId: currentLesson.id,
                    lessonTitle: currentLesson.title,
                },
            ],
            suggestedActions: [
                {
                    type: 'view_lesson',
                    label: 'Xem b√†i h·ªçc',
                    lessonId: currentLesson.id,
                },
            ],
        }
    }

    /**
     * Response khi kh√¥ng t√¨m th·∫•y g√¨
     */
    generateNoResultResponse(query, userContext) {
        let text = `üòî **Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ "${query}"**\n\n`

        // Check if query is asking about lesson content
        const isAskingAboutContent = /n·ªôi dung|content|b√†i h·ªçc|lesson/i.test(
            query
        )

        if (isAskingAboutContent && userContext.currentLesson) {
            text += `Trong b√†i h·ªçc: **${userContext.currentLesson.title}**, t√¥i kh√¥ng t√¨m th·∫•y n·ªôi dung li√™n quan. `
            text += `B·∫°n c√≥ th·ªÉ xem l·∫°i video b√†i h·ªçc ho·∫∑c m√¥ t·∫£ b√†i h·ªçc ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.\n\n`
            text += `**G·ª£i √Ω chuy·ªÉn t√πy ch·ªçn:**\n`
            text += `- Chuy·ªÉn sang "Kh√≥a h·ªçc" ƒë·ªÉ t√¨m trong to√†n b·ªô kh√≥a\n`
            text += `- Chuy·ªÉn sang "T·ªïng quan" ƒë·ªÉ ƒë·∫∑t c√¢u h·ªèi chung\n\n`
        }

        if (userContext.currentCourse) {
            text += `B·∫°n ƒëang h·ªçc kh√≥a: **${userContext.currentCourse.title}**\n\n`
            text += `**G·ª£i √Ω:**\n`
            text += `- Ki·ªÉm tra l·∫°i t·ª´ kh√≥a t√¨m ki·∫øm\n`
            text += `- Xem l·∫°i c√°c b√†i h·ªçc trong kh√≥a h·ªçc\n`
            if (isAskingAboutContent) {
                text += `- Xem video b√†i h·ªçc ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ n·ªôi dung\n`
            }
            text += `- Li√™n h·ªá gi·∫£ng vi√™n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£\n`
        } else {
            text += `**G·ª£i √Ω:**\n`
            text += `- H√£y enroll v√†o m·ªôt kh√≥a h·ªçc ƒë·ªÉ b·∫Øt ƒë·∫ßu h·ªçc\n`
            text += `- T√¨m ki·∫øm kh√≥a h·ªçc ph√π h·ª£p v·ªõi b·∫°n\n`
        }

        return {
            text,
            sources: [],
            suggestedActions: [
                {
                    type: 'browse_courses',
                    label: 'Xem c√°c kh√≥a h·ªçc',
                },
            ],
        }
    }

    /**
     * General fallback for non-course mode (friendly conversational replies)
     */
    generateGeneralFallbackResponse(query) {
        const greetingRegex = /(xin ch√†o|ch√†o|hello|hi|hey|c√≥ ·ªü ƒë√≥|are you there)/i
        if (greetingRegex.test(query)) {
            const text = `Ch√†o b·∫°n! M√¨nh l√† Gia s∆∞ AI ‚Äî m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n nh·ªØng g√¨ v·ªÅ l·∫≠p tr√¨nh ho·∫∑c h·ªçc t·∫≠p h√¥m nay?`
            return { text, sources: [], suggestedActions: [] }
        }

        const text = `M√¨nh c√≥ th·ªÉ gi√∫p tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ l·∫≠p tr√¨nh, kh√≥a h·ªçc v√† h·ªçc t·∫≠p. B·∫°n mu·ªën h·ªèi ƒëi·ªÅu g√¨ c·ª• th·ªÉ?`
        return { text, sources: [], suggestedActions: [] }
    }

    /**
     * Get messages trong conversation (optimized: combine verification with count)
     */
    async getMessages(conversationId, userId, page = 1, limit = 50, order = 'asc') {
        try {
            // Verify conversation access (allows both public advisor and private conversations)
            const conversation = await this.verifyConversationAccess(conversationId, userId)

            const [messages, total] = await Promise.all([
                prisma.chatMessage.findMany({
                    where: { conversationId },
                    orderBy: { createdAt: order === 'desc' ? 'desc' : 'asc' },
                    skip: (page - 1) * limit,
                    take: limit,
                    select: {
                        id: true,
                        senderType: true,
                        message: true,
                        messageType: true,
                        metadata: true,
                        isHelpful: true,
                        feedbackText: true,
                        createdAt: true,
                    },
                }),
                prisma.chatMessage.count({
                    where: { conversationId },
                }),
            ])

            return {
                messages,
                pagination: {
                    page,
                    limit,
                    total,
                    totalPages: Math.ceil(total / limit),
                },
            }
        } catch (error) {
            logger.error('Error getting messages:', error)
            throw error
        }
    }

    /**
     * Feedback message (helpful/not helpful)
     */
    async feedbackMessage(messageId, userId, isHelpful, feedbackText = null) {
        try {
            // Verify message belongs to user's conversation
            const message = await prisma.chatMessage.findFirst({
                where: {
                    id: messageId,
                    conversation: {
                        userId,
                    },
                },
            })

            if (!message) {
                const error = new Error('Message not found or access denied')
                error.statusCode = 404
                throw error
            }

            const updated = await prisma.chatMessage.update({
                where: { id: messageId },
                data: {
                    isHelpful,
                    feedbackText,
                },
            })

            logger.info(
                `Feedback submitted for message ${messageId}: ${isHelpful ? 'helpful' : 'not helpful'}`
            )

            return updated
        } catch (error) {
            logger.error('Error submitting feedback:', error)
            throw error
        }
    }

    /**
     * Get user's conversations
     */
    async getConversations(userId, options = {}) {
        try {
            const { isArchived = false, page = 1, limit = 20, mode } = options

            const where = {
                userId,
                isArchived,
            }

            // Add mode filter if provided
            if (mode) {
                where.mode = mode
            }

            const conversations = await prisma.conversation.findMany({
                where,
                orderBy: { lastMessageAt: 'desc' },
                skip: (page - 1) * limit,
                take: limit,
                include: {
                    course: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                            thumbnailUrl: true,
                        },
                    },
                    lesson: {
                        select: {
                            id: true,
                            title: true,
                            slug: true,
                        },
                    },
                    _count: {
                        select: { messages: true },
                    },
                    messages: {
                        take: 1,
                        orderBy: { createdAt: 'desc' },
                        select: {
                            message: true,
                            senderType: true,
                        },
                    },
                },
            })

            // Map to include lastMessage in a cleaner format
            const conversationsWithLastMessage = conversations.map(conv => ({
                ...conv,
                lastMessage: conv.messages?.[0]?.message || null,
                lastMessageSender: conv.messages?.[0]?.senderType || null,
            }))

            const total = await prisma.conversation.count({ where })

            return {
                conversations: conversationsWithLastMessage,
                pagination: {
                    page,
                    limit,
                    total,
                    totalPages: Math.ceil(total / limit),
                },
            }
        } catch (error) {
            logger.error('Error getting conversations:', error)
            throw error
        }
    }

    /**
     * Archive conversation
     */
    async archiveConversation(conversationId, userId) {
        try {
            // Verify conversation access (only allow deletion of conversations owned by user, not public advisor conversations)
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can archive their conversation
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can archive')
                error.statusCode = 403
                throw error
            }

            await prisma.conversation.update({
                where: { id: conversationId },
                data: { isArchived: true, isActive: false },
            })

            logger.info(`Archived conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error archiving conversation:', error)
            throw error
        }
    }

    /**
     * Delete conversation
     */
    async deleteConversation(conversationId, userId) {
        try {
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can delete their conversation (advisor conversations are temporary and read-only)
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can delete')
                error.statusCode = 403
                throw error
            }

            // Cascade delete messages (handled by Prisma)
            await prisma.conversation.delete({
                where: { id: conversationId },
            })

            logger.info(`Deleted conversation ${conversationId}`)
        } catch (error) {
            logger.error('Error deleting conversation:', error)
            throw error
        }
    }

    /**
     * Update conversation
     */
    async updateConversation(conversationId, userId, data) {
        try {
            const conversation = await prisma.conversation.findUnique({
                where: { id: conversationId }
            })

            if (!conversation) {
                const error = new Error('Conversation not found')
                error.statusCode = 404
                throw error
            }

            // Only owner can update their conversation (advisor conversations are read-only)
            if (conversation.userId !== userId) {
                const error = new Error('Access denied: Only conversation owner can update')
                error.statusCode = 403
                throw error
            }

            const updated = await prisma.conversation.update({
                where: { id: conversationId },
                data: {
                    title: data.title,
                },
            })

            logger.info(`Updated conversation ${conversationId}`)
            return updated
        } catch (error) {
            logger.error('Error updating conversation:', error)
            throw error
        }
    }
}

export default new AIChatService()
